 Objetivo
 Calcula a latência do evento do device (simulador) até o middleware (middts).
 - Latência em ms: latency_ms = received_timestamp - sent_timestamp
 - Uso: cole este script no Influx Data Explorer (bucket: "data") e escolha o intervalo de tempo desejado.

 Entrada (assunções / contrato)
 - Medição: `_measurement == "device_data"`
 - Tags: `sensor` (identificador do device), `source` contendo valores "simulator" ou "middts".
 - Campos:
    * `sent_timestamp` (numérico, ms desde epoch) — escrito pelo simulador.
    * `received_timestamp` (numérico, ms desde epoch) — escrito pelo middts quando ele recebe/registro o evento.
 - Observação: ambos timestamps devem ser valores numéricos (inteiros/floats em ms).

 Lógica / passos do script
 1) Leitura dos pontos do simulador: filtra `source == "simulator"` e campo `_field == "sent_timestamp"`.
 2) Leitura dos pontos do middts: filtra `source == "middts"` e campo `_field == "received_timestamp"`.
 3) `join` nas tabelas por `sensor` para parear envios e recebimentos do mesmo device.
 4) Calcula `latency_ms = received_timestamp - sent_timestamp` (em ms).
 5) Filtra eventos inválidos (ex.: quando faltar um dos timestamps ou latency < 0).
 6) Para cada par (sensor, sent_timestamp) mantém o menor latency (protege contra duplicatas).
 7) Gera saídas:
    - `latency_per_event`: linha por evento pareado (latência por evento).
    - `latency_mean_per_sensor`: média de latência por sensor (útil para visão geral).
    - `latency_p95_per_sensor`: percentil 95 por sensor (para ver cauda).

 Observações e cuidados (edge cases)
 - Clock skew: se dispositivos/simulador não estiverem com relógio sincronizado, latência pode ficar negativa ou inconsistente.
 - Tipos de campo: se `sent_timestamp` ou `received_timestamp` foram gravados como strings, o Flux falhará; verifique que são numéricos.
 - Tag `sensor` deve ser exatamente a mesma nas duas escritas (simulator e middts). Se eles usarem nomes/ids diferentes, não haverá pareamento.
 - Granularidade de janela: filtre por um intervalo de tempo apropriado no Data Explorer para evitar joins muito grandes.
 - Dados duplicados: o agrupamento por `["sensor","sent_timestamp"]` + `min(latency_ms)` remove duplicatas mantendo o menor delay observado.

 Sugestões práticas
 - Teste com um intervalo pequeno (últimos 5–15 minutos) para validar comportamento antes de rodar histórico largo.
 - Se quiser alimentar dashboards, grave o resultado agregado em uma nova medição (escrever via API) ou crie um painel no Influx/Chronograf/Grafana usando este Flux.
 - Ajuste agregações: além de média e p95, vale usar median, p99 ou histograma conforme necessidade.

 Erros comuns e como resolver
 - `undefined identifier quantile/percentile`: use `quantile(..., q: 0.95)` em Flux moderno.
 - `field type conflict`: aconteceu antes na base; verifique se os produtores enviam tipos consistentes (numérico para timestamps).
 - Resultado vazio: verificar tags (`sensor`, `source`) e intervalo de tempo; confirme que ambos os campos existem no mesmo período.

 Resultado esperado (colunas)
 - `_time`: timestamp de referência (usado no join para received event)
 - `sensor`: identificador do device
 - `sent_timestamp`: epoch ms enviado pelo simulador
 - `received_timestamp`: epoch ms gravado pelo middts
 - `latency_ms`: diferença (ms)
  
```flux
  # Flux script: latency from simulator -> middts
  # Usage: paste into Influx Data Explorer (select bucket "data" and appropriate time range)

  import "experimental"

  // Read simulator sent timestamps
  simulator = from(bucket: "iot_data")
    |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
    |> filter(fn: (r) => r._measurement == "device_data")
    |> filter(fn: (r) => r["source"] == "simulator")
    |> filter(fn: (r) => r._field == "sent_timestamp")
    |> map(fn: (r) => ({ r with sent_timestamp: r._value }))
    |> keep(columns: ["_time", "sensor", "sent_timestamp"])

  // Read middts received timestamps
  middts = from(bucket: "iot_data")
    |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
    |> filter(fn: (r) => r._measurement == "device_data")
    |> filter(fn: (r) => r["source"] == "middts")
    |> filter(fn: (r) => r._field == "received_timestamp")
    |> map(fn: (r) => ({ r with received_timestamp: r._value }))
    |> keep(columns: ["_time", "sensor", "received_timestamp"])

  // Join on sensor and compute latency
  joined = join(tables: {s: simulator, m: middts}, on: ["sensor"]) 
    |> map(fn: (r) => ({
      _time: r._time_m,
      sensor: r.sensor,
      sent_timestamp: r.sent_timestamp,
      received_timestamp: r.received_timestamp,
      latency_ms: float(v: (r.received_timestamp - r.sent_timestamp))
    }))
    |> filter(fn: (r) => exists r.sent_timestamp and exists r.received_timestamp and r.latency_ms >= 0.0)

  // Per-event: keep the minimum latency if there are duplicates
  per_event = joined
    |> group(columns: ["sensor", "sent_timestamp"]) 
    |> min(column: "latency_ms")

  // Aggregations to inspect
  per_event
    |> yield(name: "latency_per_event")

  // Optional aggregations: per-sensor summary
  per_event
    |> group(columns: ["sensor"])
    |> pivot(rowKey:["_time"], columnKey: ["sensor"], valueColumn: "latency_ms")
    |> mean(column: "latency_ms")
    |> yield(name: "latency_mean_per_sensor")

  per_event
    |> group(columns: ["sensor"]) 
    |> quantile(column: "latency_ms", q: 0.95)
    |> yield(name: "latency_p95_per_sensor")